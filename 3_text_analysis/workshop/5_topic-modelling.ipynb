{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Topic modelling\n",
    "\n",
    "See *Blei, 2003: Latent dirichlet allocation* [PDF](http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf) for a description of LDA.\n",
    "\n",
    "### Suggested readings on how to evaluate topic models\n",
    "- Reading tea leaves: how humans interpret topic models, Chang et al. (2009)\n",
    "- Machine Reading Tea Leaves: Automatically Evaluating Topic Coherence and Topic Model Quality, Lau et al.\n",
    "- http://dirichlet.net/pdf/wallach09evaluation.pdf\n",
    "- Many interesting blogs by Benjamin Schmidt, Ted Underwood etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools for investigating TMs\n",
    "\n",
    "> - [Termite](http://vis.stanford.edu/papers/termite) (Stanford)\n",
    "> - [Hiérarchie](https://nlp.stanford.edu/events/illvi2014/papers/smith-illvi2014b.pdf)\n",
    "> - [Word Embedding Visual Explorer](http://residue3.sci.utah.edu/?) [source](https://ronxin.github.io/wevi/), [paper](https://arxiv.org/abs/1411.2738)\n",
    "> - LAMVI, Sentiview, Lexos and many more.\n",
    "> - [TensorBoard](https://www.tensorflow.org/guide/summaries_and_tensorboard) (Google, PCA, VSM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to create a topic model\n",
    "- [MALLET](http://mallet.cs.umass.edu/) McCallum, Andrew Kachites.  \"MALLET: A Machine Learning for Language Toolkit.\" http://mallet.cs.umass.edu. 2002.\n",
    "- [gensim](https://radimrehurek.com/gensim/index.html) Radim Rehurek and Petr Sojka, \"Software Framework for Topic Modelling with Large Corpora\", 2010\n",
    "- [Stanford Topic Modeling Toolbox](https://nlp.stanford.edu/software/tmt/tmt-0.4/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:blue'>MANDATORY STEP</span> Setup and Initialize the Notebook\n",
    "Use the **play** button, or press **Shift-Enter** to execute a code cell (select it first). The code imports Python libraries and frameworks, and initializes the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"6e54182f-3adf-40d0-9588-181a6c02f226\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"6e54182f-3adf-40d0-9588-181a6c02f226\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"6e54182f-3adf-40d0-9588-181a6c02f226\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '6e54182f-3adf-40d0-9588-181a6c02f226' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.13.0.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"6e54182f-3adf-40d0-9588-181a6c02f226\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"6e54182f-3adf-40d0-9588-181a6c02f226\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"6e54182f-3adf-40d0-9588-181a6c02f226\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '6e54182f-3adf-40d0-9588-181a6c02f226' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.13.0.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"6e54182f-3adf-40d0-9588-181a6c02f226\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Folded Code\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import common.utility\n",
    "from common.model_utility import ModelUtility\n",
    "from common.plot_utility import layout_algorithms, PlotNetworkUtility\n",
    "import common.widgets_utility as wf\n",
    "from common.network_utility import NetworkUtility, DISTANCE_METRICS, NetworkMetricHelper\n",
    "#import common.vectorspace_utility\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import types\n",
    "import ipywidgets as widgets\n",
    "import logging\n",
    "import bokeh.models as bm\n",
    "import bokeh.palettes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pivottablejs import pivot_ui\n",
    "from IPython.display import display, HTML, clear_output, IFrame\n",
    "from itertools import product\n",
    "from bokeh.io import output_file, push_notebook\n",
    "from bokeh.core.properties import value, expr\n",
    "from bokeh.transform import transform, jitter\n",
    "from bokeh.layouts import row, column, widgetbox\n",
    "from bokeh.plotting import figure, show, output_notebook, output_file\n",
    "from bokeh.models.widgets import DataTable, DateFormatter, TableColumn\n",
    "from bokeh.models import ColumnDataSource, CustomJS\n",
    "\n",
    "logger = logging.getLogger('explore-topic-models')\n",
    "TOOLS = \"pan,wheel_zoom,box_zoom,reset,previewsave\"\n",
    "AGGREGATES = { 'mean': np.mean, 'sum': np.sum, 'max': np.max, 'std': np.std }\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "pd.set_option('precision', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:blue'>MANDATORY STEP</span> Select LDA Topic Model\n",
    "- Select one of the previously computed and prepared topic models that you wan't to use in subsequent steps.\n",
    "- Models are computed in batch in accordance to \n",
    "<a href=\"./images/workflow-prepare.svg\">process flow</a> used in the *Digitala modeller* project.\n",
    "- Note that subsequent code cells are NOT updated (executed) automatically when a new model is selected.\n",
    "- Use the **play** button, or press **Shift-Enter** to execute the selected cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aff08dc4f78542138b9248f78555d6fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Topic model', layout=Layout(width='75%'), options=('20180910_SOU_1990_T50…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hidden code: Select current model state\n",
    "class ModelState:\n",
    "    \n",
    "    def __init__(self, data_folder):\n",
    "        \n",
    "        self.data_folder = data_folder\n",
    "        self.basenames = ModelUtility.get_model_names(data_folder)\n",
    "        self.basename = self.basenames[0]\n",
    "        self.on_set_model_callback = None\n",
    "        \n",
    "    def set_model(self, basename=None):\n",
    "\n",
    "        basename = basename or self.basename\n",
    "        \n",
    "        self.basename = basename\n",
    "        self.topic_keys = ModelUtility.get_topic_keys(self.data_folder, basename)\n",
    "        state.max_alpha = self.topic_keys.alpha.max()\n",
    "        self.topic_overview = ModelUtility\\\n",
    "            .get_result_model_sheet(self.data_folder, basename, 'topic_tokens')\n",
    "        self.document_topic_weights = ModelUtility\\\n",
    "            .get_result_model_sheet(self.data_folder, basename, 'doc_topic_weights')\\\n",
    "            .drop('Unnamed: 0', axis=1, errors='ignore')\n",
    "        self.topic_token_weights = ModelUtility\\\n",
    "            .get_result_model_sheet(self.data_folder, basename, 'topic_token_weights')\\\n",
    "            .drop('Unnamed: 0', axis=1, errors='ignore')\\\n",
    "            .dropna(subset=['token'])\n",
    "        self._years = list(range(\n",
    "            self.document_topic_weights.year.min(), self.document_topic_weights.year.max() + 1))\n",
    "        self.min_year = min(self._years)\n",
    "        self.max_year = max(self._years)\n",
    "        self.years = [None] + self._years\n",
    "        self.n_topics = self.topic_overview.topic_id.max() + 1\n",
    "        # https://stackoverflow.com/questions/44561609/how-does-mallet-set-its-default-hyperparameters-for-lda-i-e-alpha-and-beta\n",
    "        self.initial_alpha = 0.0  # 5.0 / self.n_topics if 'mallet' in state.basename else 1.0 / self.n_topics\n",
    "        self.initial_beta = 0.0  # 0.01 if 'mallet' in basename else 1.0 / self.n_topics\n",
    "        self._lda = None\n",
    "        self._topic_titles = None\n",
    "        self.corpus_documents = ModelUtility.get_corpus_documents(self.data_folder, self.basename).set_index('document_id')\n",
    "        print(\"Current model: \" + self.basename.upper())\n",
    "        \n",
    "        if self.on_set_model_callback is not None:\n",
    "            self.on_set_model_callback(self)\n",
    "            \n",
    "        # _fix_topictokens()\n",
    "        return self\n",
    "    \n",
    "    #def get_document_topic_weights(self, year=None, topic_id=None):\n",
    "    #    df = self.document_topic_weights\n",
    "    #    if year is None and topic_id is None:\n",
    "    #        return df\n",
    "    #    if topic_id is None:\n",
    "    #        return df[(df.year == year)]\n",
    "    #    if year is None:\n",
    "    #        return df[(df.topic_id == topic_id)]\n",
    "    #    return df[(df.year == year)&(df.topic_id == topic_id)]\n",
    "    \n",
    "    def get_unique_topic_ids(self):\n",
    "        return self.document_topic_weights['topic_id'].unique()\n",
    "    \n",
    "    #def get_topic_weight_by_year_or_document(self, key='mean', pivot_column=None):\n",
    "    #    \n",
    "    #    if pivot_column is None:\n",
    "    #        pivot_column = 'year' if year is None else 'document_id'    \n",
    "    #        \n",
    "    #    df = self.document_topic_weights(year) \\\n",
    "    #        .groupby([pivot_column,'topic_id']) \\\n",
    "    #        .agg(AGGREGATES[key])[['weight']].reset_index()\n",
    "    #    return df, pivot_column\n",
    "    \n",
    "    #return self.get_document_topic_weight_by_pivot_column(pivot_column, key, filter={'column': 'year', 'values': [year]})\n",
    "    \n",
    "    def get_document_topic_weight_by_filter(self, filters=None):\n",
    "        df = self.document_topic_weights.query('weight > 0')\n",
    "        for filter in (filters or []):\n",
    "            if 'query' in filter.keys():\n",
    "                df = df.query(filter['query'])\n",
    "            elif isinstance(filter['value'], str):\n",
    "                df = df[(df[filter['column']]==filter['value'])]\n",
    "            elif isinstance(filter['value'], list):\n",
    "                df = df[(df[filter['column']].isin(filter['value']))]\n",
    "        return df\n",
    "    \n",
    "    def get_document_topic_weight_by_pivot_column(self, pivot_column, key='mean', filters=None):\n",
    "        df = self.get_document_topic_weight_by_filter(filters)\n",
    "        df = df.groupby([pivot_column, 'topic_id'])\\\n",
    "               .agg(AGGREGATES[key])[['weight']].reset_index()\n",
    "        return df[df.weight > 0]\n",
    "    \n",
    "    def get_topic_tokens_dict(self, topic_id, n_top=200):\n",
    "        return self.get_topic_tokens(topic_id)\\\n",
    "            .sort_values(['weight'], ascending=False)\\\n",
    "            .head(n_top)[['token', 'weight']]\\\n",
    "            .set_index('token').to_dict()['weight']\n",
    "\n",
    "    def compute_topic_terms_vector_space(self, n_words=100):\n",
    "        '''\n",
    "        Create an align topic-term vector space of top n_words from each topic\n",
    "        '''\n",
    "        unaligned_vector_dicts = ( self.get_topic_tokens_dict(topic_id, n_words) for topic_id in range(0, self.n_topics) )\n",
    "        X, feature_names = ModelUtility.compute_and_align_vector_space(unaligned_vector_dicts)\n",
    "        return X, feature_names\n",
    "\n",
    "    def get_lda(self):\n",
    "        raise Exception(\"Use of LDA model disabled in this Notebook\")\n",
    "        '''\n",
    "        Get gensim model. Only used for pyLDAvis display\n",
    "        '''\n",
    "        if self._lda is None:\n",
    "            filename = os.path.join(self.data_folder, self.basename, 'gensim_model_{}.gensim.gz'.format(self.basename))\n",
    "            if os.path.isfile(filename):\n",
    "                self._lda = LdaModel.load(filename)\n",
    "                print('LDA model loaded...')\n",
    "            else:\n",
    "                print('LDA not found on disk...')\n",
    "        return self._lda \n",
    "    \n",
    "    def get_topic_titles(self, n_words=100, cache=True):\n",
    "        if cache and self._topic_titles is not None:\n",
    "            return self._topic_titles\n",
    "        _topic_titles = ModelUtility.get_topic_titles(state.topic_token_weights, n_words=n_words)\n",
    "        self._topic_titles = _topic_titles if cache else None\n",
    "        return _topic_titles\n",
    "    \n",
    "    def get_topic_tokens(self, topic_id, max_n_words=500):\n",
    "        tokens = state.topic_token_weights\\\n",
    "            .loc[lambda x: x.topic_id == topic_id]\\\n",
    "            .sort_values('weight',ascending=False)[:max_n_words]\n",
    "        return tokens\n",
    "    \n",
    "    def get_topic_alphas(self):\n",
    "        tokens = state.topic_token_weights\\\n",
    "            .loc[lambda x: x.topic_id == topic_id]\\\n",
    "            .sort_values('weight',ascending=False)[:max_n_words]\n",
    "        alpas = ModelUtility.get_topic_alphas\n",
    "        return tokens\n",
    "    \n",
    "    def get_topic_year_aggregate_weights(self, fn, threshold):\n",
    "        df = self.document_topic_weights[(self.document_topic_weights.weight > 0.001)]\n",
    "        df = df.groupby(['year', 'topic_id']).agg(fn)['weight'].reset_index()\n",
    "        df = df[(df.weight>=threshold)]\n",
    "        return df\n",
    "    \n",
    "    def get_topic_proportions(self):\n",
    "        corpus_documents = self.get_corpus_documents()\n",
    "        document_topic_weights = self.document_topic_weights\n",
    "        topic_proportion = ModelUtility.compute_topic_proportions(document_topic_weights, corpus_documents)\n",
    "        return topic_proportion\n",
    "    \n",
    "    def get_corpus_documents(self):\n",
    "        #if self.corpus_documents is None:\n",
    "        #    self.corpus_documents = ModelUtility.get_corpus_documents(self.data_folder, self.basename)\n",
    "        return self.corpus_documents\n",
    "\n",
    "    def on_set_model(self, callback):\n",
    "        self.on_set_model_callback = callback\n",
    "        return self\n",
    "        \n",
    "def on_set_model_handler(state):\n",
    "\n",
    "    if 'report_name' in state.corpus_documents:\n",
    "        return\n",
    "    \n",
    "    state.source_documents = pd.read_csv('data/SOU_1990_index.csv', sep='\\t', header=None, names=['year', 'report_id', 'report_name'])\n",
    "    state.corpus_documents['report_id'] = state.corpus_documents.document.str.split('_').apply(lambda x: x[1]).astype(np.int64)\n",
    "    state.corpus_documents['report_name'] = pd.merge(state.corpus_documents, state.source_documents, how='inner', on=['year', 'report_id']).report_name\n",
    "    state.corpus_documents['report_name'] = state.corpus_documents.apply(lambda x: '{}-{} {}'.format(x['year'], x['report_id'], x['report_name'])[:50], axis=1)\n",
    "    state.document_topic_weights['report_name'] = pd.merge(state.document_topic_weights, state.corpus_documents, left_on='document_id', right_index=True).report_name\n",
    "\n",
    "def select_model_main(state):\n",
    "    \n",
    "    basename_widget = widgets.Dropdown(\n",
    "        options=state.basenames,\n",
    "        value=state.basename,\n",
    "        description='Topic model',\n",
    "        disabled=False,\n",
    "        layout=widgets.Layout(width='75%')\n",
    "    )\n",
    "    \n",
    "    w = widgets.interactive(state.set_model, basename=basename_widget, state=widgets.fixed(state))\n",
    "    display(widgets.VBox((basename_widget,) + (w.children[-1],)))\n",
    "    w.update()\n",
    "\n",
    "state = ModelState('./data').on_set_model(on_set_model_handler)\n",
    "\n",
    "select_model_main(state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### The Alpha Hyperparameter\n",
    "\n",
    "- See [Probabalistic Topic Models](http://psiexp.ss.uci.edu/research/papers/SteyversGriffithsLSABookFormatted.pdf) for a description of LDA hyperparameters.\n",
    "- The **alpha** hyperparameter affects the document-topic distribution.\n",
    "- The LDA model is said to be *symmetric* if the same alpha value is used for all topics, and *assymetric* if it can vary per topic.\n",
    "- If a assymetric model, then high alphas can indicate a \"stopwords\" topic (frequent words), and low alphas can indicate bogus topics.\n",
    "- This chart is of no value for symmetric models. \n",
    "- See also: [stackexchange what-exactly-is-the-alpha-in-the-dirichlet-distribution](https://stats.stackexchange.com/questions/244917/what-exactly-is-the-alpha-in-the-dirichlet-distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c3a9d3eb0d439193b90ffd3f1a0bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='alpha_plot' style='line-height: 20px;'>Hover topics to display words!<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Alpha / Lambda Plot\n",
    "\n",
    "_topic_keys = ModelUtility.get_topic_keys(state.data_folder, state.basename)\n",
    "\n",
    "def plot_alpha(df):\n",
    "\n",
    "    source = ColumnDataSource(df)\n",
    "    p = figure(x_range=df.topic.values,plot_width=900, plot_height=400, title='',\n",
    "               tools=TOOLS, toolbar_location=\"above\")\n",
    "    p.xaxis[0].axis_label = 'Topic'\n",
    "    p.yaxis[0].axis_label = 'Alpha'\n",
    "    p.xaxis.major_label_orientation = 1.0\n",
    "    p.y_range.start = 0.0\n",
    "    x_axis_type = 'enum'\n",
    "    p.xgrid.visible = False\n",
    "\n",
    "    glyph = bm.glyphs.VBar(x='topic', top='alpha', bottom=0, width=0.5, fill_color='color')\n",
    "    cr = p.add_glyph(source, glyph)\n",
    "\n",
    "    titles = ModelUtility.get_topic_titles(state.topic_token_weights, n_words=100)\n",
    "    p.add_tools(bm.HoverTool(tooltips=None, callback=wf.WidgetUtility.glyph_hover_callback(\n",
    "        source, 'topic_id', titles.index, titles, 'alpha_plot'), renderers=[cr]))\n",
    "        \n",
    "    return p\n",
    "\n",
    "def display_alpha(output_format, sort_by, window):\n",
    "    global state\n",
    "    palette = bokeh.palettes.PiYG[4]\n",
    "    topic_keys = ModelUtility.get_topic_keys(state.data_folder, state.basename).reset_index()\n",
    "    topic_keys = topic_keys[((topic_keys.alpha >= window[0]) & (topic_keys.alpha <= window[1]))]\n",
    "    topic_keys['topic'] = topic_keys.topic_id.apply(lambda x: str(x))\n",
    "    topic_keys['color'] = palette[1]  # topic_keys.alpha.apply(lambda x: palette[1] if x >= state.initial_alpha else palette[2])\n",
    "    if sort_by.lower() == 'alpha':\n",
    "        topic_keys = topic_keys.sort_values('alpha', axis=0)\n",
    "    if output_format == 'Chart':\n",
    "        p = plot_alpha(topic_keys)\n",
    "        show(p)\n",
    "    else:\n",
    "        source = bm.ColumnDataSource(topic_keys)\n",
    "        columns = [\n",
    "            TableColumn(field=\"topic_id\", title=\"ID\"),\n",
    "            TableColumn(field=\"alpha\", title=\"Alpha\"),\n",
    "            TableColumn(field=\"tokens\", title=\"Tokens\"),\n",
    "        ]\n",
    "        data_table = DataTable(source=source, columns=columns, width=950, height=600)\n",
    "        show(widgetbox(data_table))\n",
    "\n",
    "def plot_alpha_main():\n",
    "    \n",
    "    za = wf.BaseWidgetUtility(\n",
    "        text_id='alpha_plot',\n",
    "        text=wf.create_text_widget('alpha_plot',default_value='Hover topics to display words!'),\n",
    "        output_format=wf.create_select_widget('Format', ['Chart', 'Table'], default='Chart'),\n",
    "        sort_by=wf.create_select_widget('Sort by', ['Topic', 'Alpha'], default='Alpha'),\n",
    "        window=widgets.FloatRangeSlider(\n",
    "            description='Window',\n",
    "            min=0, max=state.max_alpha + 0.1,\n",
    "            step=0.01,\n",
    "            value=(0, state.max_alpha + 0.1),  # (state.initial_alpha, state.max_alpha + 0.1),\n",
    "            continuous_update=False\n",
    "        )\n",
    "    )\n",
    "    za.next_topic_id = za.create_next_id_button('topic_id', state.n_topics)\n",
    "\n",
    "    wa = widgets.interactive(\n",
    "        display_alpha,\n",
    "        output_format=za.output_format,\n",
    "        sort_by=za.sort_by,\n",
    "        window=za.window\n",
    "    )\n",
    "    za.text.layout = widgets.Layout(width='95%') #  , height='120px')\n",
    "    wa.children[-1].layout = widgets.Layout(width='98%')\n",
    "\n",
    "    display(widgets.VBox([\n",
    "        za.text,\n",
    "        widgets.HBox([za.output_format, za.window, za.sort_by]),\n",
    "        widgets.HBox([wa.children[-1]])\n",
    "    ]))\n",
    "    wa.update()\n",
    "    \n",
    "plot_alpha_main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb0ed47d1a5e48ceb0c64db6f52e2a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='dirichlet_alpha_plot' style='line-height: 20px;'>Hover topics to displ…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dir(alpha) test sample\n",
    "def plot_dirichlet_alpha_sample(df):\n",
    "\n",
    "    source = ColumnDataSource(df)\n",
    "    p = figure(x_range=df.topic.values,plot_width=900, plot_height=400, title='',\n",
    "               tools=TOOLS, toolbar_location=\"above\")\n",
    "    p.xaxis[0].axis_label = 'Topic'\n",
    "    p.yaxis[0].axis_label = 'Value'\n",
    "    p.xaxis.major_label_orientation = 1.0\n",
    "    p.y_range.start = 0.0\n",
    "    x_axis_type = 'enum'\n",
    "    p.xgrid.visible = False\n",
    "\n",
    "    glyph = bm.glyphs.VBar(x='topic', top='value', bottom=0, width=0.5, fill_color='color')\n",
    "    cr = p.add_glyph(source, glyph)\n",
    "\n",
    "    titles = ModelUtility.get_topic_titles(state.topic_token_weights, n_words=100)\n",
    "    p.add_tools(bm.HoverTool(tooltips=None, callback=wf.WidgetUtility.glyph_hover_callback(\n",
    "        source, 'topic_id', titles.index, titles, 'dirichlet_alpha_plot'), renderers=[cr]))\n",
    "        \n",
    "    return p\n",
    "\n",
    "def display_dirichlet_alpha_draw():\n",
    "    global state\n",
    "    palette = bokeh.palettes.PiYG[4]\n",
    "    topic_keys = ModelUtility.get_topic_keys(state.data_folder, state.basename).reset_index()\n",
    "    topic_keys['topic'] = topic_keys.topic_id.apply(lambda x: str(x))\n",
    "    topic_keys['color'] = palette[1] # topic_keys.alpha.apply(lambda x: palette[1] if x >= state.initial_alpha else palette[2])\n",
    "    topic_keys['value'] = np.random.dirichlet(topic_keys.alpha)\n",
    "\n",
    "    p = plot_dirichlet_alpha_sample(topic_keys)\n",
    "    show(p)\n",
    "\n",
    "def draw_dirichlet_alpha_main():\n",
    "    \n",
    "    zd = wf.BaseWidgetUtility(\n",
    "        text_id='dirichlet_alpha_plot',\n",
    "        text=wf.create_text_widget('dirichlet_alpha_plot',default_value='Hover topics to display words!'),\n",
    "    )\n",
    "    zd.refresh_button = widgets.Button(\n",
    "        description='Draw',\n",
    "        disabled=False,\n",
    "        button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "        tooltip='Click me',\n",
    "        icon='check'\n",
    "    )\n",
    "\n",
    "    def on_refresh_button_clicked(b):\n",
    "        wd.update()\n",
    "\n",
    "    zd.refresh_button.on_click(on_refresh_button_clicked)\n",
    "\n",
    "    wd = widgets.interactive(display_dirichlet_alpha_draw)\n",
    "    zd.text.layout = widgets.Layout(width='95%')\n",
    "    wd.children[-1].layout = widgets.Layout(width='98%')\n",
    "\n",
    "    display(widgets.VBox([\n",
    "        zd.text,\n",
    "        widgets.HBox([zd.refresh_button]),\n",
    "        widgets.HBox([wd.children[-1]])\n",
    "    ]))\n",
    "    wd.update()\n",
    "    \n",
    "draw_dirichlet_alpha_main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic-Word Distribution - Wordcloud and Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e050fcf097242f9ab63c9fb38b603c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='tx02' style='line-height: 20px;'></span>\", placeholder=''), HBox(child…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display LDA topic's token wordcloud\n",
    "opts = { 'max_font_size': 100, 'background_color': 'white', 'width': 900, 'height': 600 }\n",
    "\n",
    "import wordcloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_topic_distribution_widgets(callback, state, text_id, output_options=None, word_count=(1, 100, 50)):\n",
    "    \n",
    "    output_options = output_options or []\n",
    "    wc = wf.BaseWidgetUtility(\n",
    "        n_topics=state.n_topics,\n",
    "        text_id=text_id,\n",
    "        text=wf.create_text_widget(text_id),\n",
    "        topic_id=widgets.IntSlider(\n",
    "            description='Topic ID', min=0, max=state.n_topics - 1, step=1, value=0, continuous_update=False),\n",
    "        word_count=widgets.IntSlider(\n",
    "            description='#Words', min=word_count[0], max=word_count[1], step=1, value=word_count[2], continuous_update=False),\n",
    "        output_format=wf.create_select_widget('Format', output_options, default=output_options[0], layout=widgets.Layout(width=\"200px\")),\n",
    "        progress = widgets.IntProgress(min=0, max=4, step=1, value=0, layout=widgets.Layout(width=\"95%\"))\n",
    "    )\n",
    "\n",
    "    wc.prev_topic_id = wc.create_prev_id_button('topic_id', state.n_topics)\n",
    "    wc.next_topic_id = wc.create_next_id_button('topic_id', state.n_topics)\n",
    "\n",
    "    iw = widgets.interactive(\n",
    "        callback,\n",
    "        topic_id=wc.topic_id,\n",
    "        n_words=wc.word_count,\n",
    "        output_format=wc.output_format,\n",
    "        widget_container=widgets.fixed(wc)\n",
    "    )\n",
    "\n",
    "    display(widgets.VBox([\n",
    "        wc.text,\n",
    "        widgets.HBox([wc.prev_topic_id, wc.next_topic_id, wc.topic_id, wc.word_count, wc.output_format]),\n",
    "        wc.progress,\n",
    "        iw.children[-1]\n",
    "    ]))\n",
    "\n",
    "    iw.update()\n",
    "\n",
    "def plot_wordcloud(df_data, token='token', weight='weight', figsize=(14, 14/1.618), **args):\n",
    "    token_weights = dict({ tuple(x) for x in df_data[[token, weight]].values })\n",
    "    image = wordcloud.WordCloud(**args,)\n",
    "    image.fit_words(token_weights)\n",
    "    plt.figure(figsize=figsize) #, dpi=100)\n",
    "    plt.imshow(image, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "def display_wordcloud(topic_id=0, n_words=100, output_format='Wordcloud', widget_container=None):\n",
    "    widget_container.progress.value = 1\n",
    "    df_temp = state.topic_token_weights.loc[(state.topic_token_weights.topic_id == topic_id)]\n",
    "    tokens = state.get_topic_titles(n_words=n_words, cache=True).iloc[topic_id]\n",
    "    widget_container.value = 2\n",
    "    widget_container.text.value = 'ID {}: {}'.format(topic_id, tokens)\n",
    "    if output_format == 'Wordcloud':\n",
    "        plot_wordcloud(df_temp, 'token', 'weight', max_words=n_words, **opts)\n",
    "    elif output_format == 'Table':\n",
    "        widget_container.progress.value = 3\n",
    "        df_temp = state.get_topic_tokens(topic_id, n_words)\n",
    "        widget_container.progress.value = 4\n",
    "        display(HTML(df_temp.to_html()))\n",
    "    else:\n",
    "        display(pivot_ui(state.get_topic_tokens(topic_id, n_words)))\n",
    "    widget_container.progress.value = 0\n",
    "\n",
    "display_topic_distribution_widgets(display_wordcloud, state, 'tx02', ['Wordcloud', 'Table', 'Pivot'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic-Word Distribution - Chart\n",
    "The following chart shows the word distribution for each selected topic. You can zoom in on the left chart. The distribution seems to follow [Zipf's law](https://en.wikipedia.org/wiki/Zipf%27s_law) as (perhaps) expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486421cb0c4d43dc96577303951f1b5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='wc01' style='line-height: 20px;'></span>\", placeholder=''), HBox(child…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display topic's word distribution\n",
    "\n",
    "def plot_topic_word_distribution(tokens, **args):\n",
    "\n",
    "    source = ColumnDataSource(tokens)\n",
    "\n",
    "    p = figure(toolbar_location=\"right\", **args)\n",
    "\n",
    "    cr = p.circle(x='xs', y='ys', source=source)\n",
    "\n",
    "    label_style = dict(level='overlay', text_font_size='8pt', angle=np.pi/6.0)\n",
    "\n",
    "    text_aligns = ['left', 'right']\n",
    "    for i in [0, 1]:\n",
    "        label_source = ColumnDataSource(tokens.iloc[i::2])\n",
    "        labels = bm.LabelSet(x='xs', y='ys', text_align=text_aligns[i], text='token', text_baseline='middle',\n",
    "                          y_offset=5*(1 if i == 0 else -1),\n",
    "                          x_offset=5*(1 if i == 0 else -1),\n",
    "                          source=label_source, **label_style)\n",
    "        p.add_layout(labels)\n",
    "\n",
    "    p.xaxis[0].axis_label = 'Token #'\n",
    "    p.yaxis[0].axis_label = 'Probability%'\n",
    "    p.ygrid.grid_line_color = None\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.axis.axis_line_color = None\n",
    "    p.axis.major_tick_line_color = None\n",
    "    p.axis.major_label_text_font_size = \"6pt\"\n",
    "    p.axis.major_label_standoff = 0\n",
    "    return p\n",
    "\n",
    "def plot_topic_tokens_charts(tokens, flag=True):\n",
    "\n",
    "    if flag:\n",
    "        left = plot_topic_word_distribution(tokens, plot_width=1000, plot_height=500, title='', tools='box_zoom,wheel_zoom,pan,reset')\n",
    "        show(left)\n",
    "        return\n",
    "\n",
    "    left = plot_topic_word_distribution(tokens, plot_width=450, plot_height=500, title='', tools='box_zoom,wheel_zoom,pan,reset')\n",
    "    right = plot_topic_word_distribution(tokens, plot_width=450, plot_height=500, title='', tools='pan')\n",
    "\n",
    "    source = ColumnDataSource({'x':[], 'y':[], 'width':[], 'height':[]})\n",
    "    left.x_range.callback = create_js_callback('x', 'width', source)\n",
    "    left.y_range.callback = create_js_callback('y', 'height', source)\n",
    "\n",
    "    rect = bm.Rect(x='x', y='y', width='width', height='height', fill_alpha=0.0, line_color='blue', line_alpha=0.4)\n",
    "    right.add_glyph(source, rect)\n",
    "\n",
    "    show(row(left, right))\n",
    "\n",
    "def display_topic_tokens(topic_id=0, n_words=100, output_format='Chart', widget_container=None):\n",
    "    widget_container.forward()\n",
    "    tokens = state.get_topic_tokens(topic_id=topic_id).\\\n",
    "        copy()\\\n",
    "        .drop('topic_id', axis=1)\\\n",
    "        .assign(weight=lambda x: 100.0 * x.weight)\\\n",
    "        .sort_values('weight', axis=0, ascending=False)\\\n",
    "        .reset_index()\\\n",
    "        .head(n_words)\n",
    "    if output_format == 'Chart':\n",
    "        widget_container.forward()\n",
    "        tokens = tokens.assign(xs=tokens.index, ys=tokens.weight)\n",
    "        plot_topic_tokens_charts(tokens)\n",
    "        widget_container.forward()\n",
    "    elif output_format == 'Table':\n",
    "        #display(tokens)\n",
    "        display(HTML(tokens.to_html()))\n",
    "    else:\n",
    "        display(pivot_ui(tokens))\n",
    "    widget_container.reset()\n",
    "        \n",
    "display_topic_distribution_widgets(display_topic_tokens, state, 'wc01', ['Chart', 'Table'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic's Trend Over Time or Documents\n",
    "- Displays topic's share over documents or time.\n",
    "- Note that source documents (i.e. SOU reports) are splitted into 1000 word chunks (LDA document) by the topic modelling process\n",
    "- If \"SOU Report\" or \"Year\" is selected then the **max** or **mean** weight is selected from corresponding LDA documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d25e7c13c9814f5db9482eec1eeadca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='topic_share_plot' style='line-height: 20px;'></span>\", placeholder='')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a topic's yearly weight over time in selected LDA topic model\n",
    "import numpy as np\n",
    "import math\n",
    "import bokeh.plotting\n",
    "from bokeh.models import ColumnDataSource, DataRange1d, Plot, LinearAxis, Grid\n",
    "from bokeh.models.glyphs import VBar\n",
    "from bokeh.io import curdoc, show\n",
    "\n",
    "def plot_topic_trend(df, pivot_column, value_column, x_label=None, y_label=None):\n",
    "\n",
    "    xs = df[pivot_column].astype(np.str)\n",
    "    p = bokeh.plotting.figure(x_range=xs, plot_width=1000, plot_height=700, title='', tools=TOOLS, toolbar_location=\"right\")\n",
    "\n",
    "    glyph = p.vbar(x=xs, top=df[value_column], width=0.5, fill_color=\"#b3de69\")\n",
    "    p.xaxis.major_label_orientation = math.pi/4\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.xaxis[0].axis_label = (x_label or '').title()\n",
    "    p.yaxis[0].axis_label = (y_label or '').title()\n",
    "    p.y_range.start = 0.0\n",
    "    #p.y_range.end = 1.0\n",
    "    p.x_range.range_padding = 0.01\n",
    "    return p\n",
    "\n",
    "def display_topic_trend(topic_id, pivot_config, value_column, widgets_container, output_format='Chart', state=None, threshold=0.01):\n",
    "    \n",
    "    pivot_column = pivot_config['pivot_column']\n",
    "    tokens = state.get_topic_titles(n_words=200, cache=True).iloc[topic_id]\n",
    "    widgets_container.text.value = 'ID {}: {}'.format(topic_id, tokens)\n",
    "    value_column = value_column if pivot_column is not None else 'weight'\n",
    "    \n",
    "    df = state.document_topic_weights[(state.document_topic_weights.topic_id==topic_id)]\n",
    "    \n",
    "    if pivot_column is not None:\n",
    "        df = df.groupby([pivot_column]).agg([np.mean, np.max])['weight'].reset_index()\n",
    "        df.columns = [pivot_column, 'mean', 'max' ]\n",
    "        df = df[(df[value_column] > threshold)]\n",
    "        \n",
    "    if output_format == 'Table':\n",
    "        display(df)\n",
    "    else:\n",
    "        x_label = pivot_column.title()\n",
    "        y_label = value_column.title() + ('weight' if value_column != 'weight' else '')\n",
    "        p = plot_topic_trend(df, pivot_column, value_column, x_label=x_label, y_label=y_label)\n",
    "        show(p)\n",
    "\n",
    "def create_topic_trend_widgets(state):\n",
    "    pivot_options = {\n",
    "        '': { 'pivot_column': None, 'filter': None },\n",
    "        'SOU Report': { 'pivot_column': 'report_name', 'filter': None },\n",
    "        'Year': { 'pivot_column': 'year', 'filter': None },\n",
    "        'LDA Document': { 'pivot_column': 'document_id', 'filter': None }\n",
    "    } \n",
    "    wc = wf.BaseWidgetUtility(\n",
    "        n_topics=state.n_topics,\n",
    "        text_id='topic_share_plot',\n",
    "        text=wf.create_text_widget('topic_share_plot'),\n",
    "        #year=wf.create_select_widget('Year', options=state.years, value=state.years[-1]),\n",
    "        pivot_config=widgets.Dropdown(\n",
    "            options=pivot_options,\n",
    "            value=pivot_options['SOU Report'],\n",
    "            description='Group by'\n",
    "        ),\n",
    "        threshold=widgets.FloatSlider(description='Threshold', min=0.0, max=0.25, step=0.01, value=0.10, continuous_update=False),\n",
    "        topic_id=widgets.IntSlider(description='Topic ID', min=0, max=state.n_topics - 1, step=1, value=0, continuous_update=False),\n",
    "        output_format=wf.create_select_widget('Format', ['Chart', 'Table'], default='Chart'),\n",
    "        progress=widgets.IntProgress(min=0, max=4, step=1, value=0, layout=widgets.Layout(width=\"50%\")),\n",
    "        aggregate=widgets.Dropdown(options=['max', 'mean'], value='max', description='Aggregate')\n",
    "    )\n",
    "\n",
    "    wc.prev_topic_id = wc.create_prev_id_button('topic_id', state.n_topics)\n",
    "    wc.next_topic_id = wc.create_next_id_button('topic_id', state.n_topics)\n",
    "\n",
    "    iw = widgets.interactive(\n",
    "        display_topic_trend,\n",
    "        topic_id=wc.topic_id,\n",
    "        pivot_config=wc.pivot_config,\n",
    "        value_column=wc.aggregate,\n",
    "        widgets_container=widgets.fixed(wc),\n",
    "        output_format=wc.output_format,\n",
    "        state=widgets.fixed(state),\n",
    "        threshold=wc.threshold\n",
    "    )\n",
    "    display(widgets.VBox([\n",
    "        wc.text,\n",
    "        widgets.HBox([wc.prev_topic_id, wc.next_topic_id, wc.pivot_config, wc.aggregate, wc.output_format]),\n",
    "        widgets.HBox([wc.topic_id, wc.threshold, wc.progress]),\n",
    "        iw.children[-1]\n",
    "    ]))\n",
    "    \n",
    "    iw.update()\n",
    "    \n",
    "create_topic_trend_widgets(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic to Document Network\n",
    "The green nodes are documents, and blue nodes are topics. The edges (lines) indicates the strength of a topic in the connected document. The width of the edge is proportinal to the strength of the connection. Note that only edges with a strength above the certain threshold are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d989119ad64e1aa9fe3ff23afde106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='nx_id1' style='line-height: 20px;display: inline; height='400px''></sp…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize year-to-topic network by means of topic-document-weights\n",
    "     \n",
    "def plot_topic_year_network(network, layout, scale=1.0, titles=None):\n",
    "\n",
    "    year_nodes, topic_nodes = NetworkUtility.get_bipartite_node_set(network, bipartite=0)  \n",
    "    \n",
    "    year_source = NetworkUtility.get_node_subset_source(network, layout, year_nodes)\n",
    "    topic_source = NetworkUtility.get_node_subset_source(network, layout, topic_nodes)\n",
    "    lines_source = NetworkUtility.get_edges_source(network, layout, scale=6.0, normalize=False)\n",
    "    \n",
    "    edges_alphas = NetworkMetricHelper.compute_alpha_vector(lines_source.data['weights'])\n",
    "    \n",
    "    lines_source.add(edges_alphas, 'alphas')\n",
    "    \n",
    "    p = figure(plot_width=1000, plot_height=600, x_axis_type=None, y_axis_type=None, tools=TOOLS)\n",
    "    \n",
    "    r_lines = p.multi_line(\n",
    "        'xs', 'ys', line_width='weights', alpha='alphas', color='black', source=lines_source\n",
    "    )\n",
    "    r_years = p.circle(\n",
    "        'x','y', size=40, source=year_source, color='lightgreen', level='overlay', line_width=1,alpha=1.0\n",
    "    )\n",
    "    \n",
    "    r_topics = p.circle('x','y', size=25, source=topic_source, color='skyblue', level='overlay', alpha=1.00)\n",
    "    \n",
    "    p.add_tools(bm.HoverTool(renderers=[r_topics], tooltips=None, callback=wf.WidgetUtility.\\\n",
    "        glyph_hover_callback(topic_source, 'node_id', text_ids=titles.index, text=titles, element_id='nx_id1'))\n",
    "    )\n",
    "\n",
    "    text_opts = dict(\n",
    "        x='x', y='y', text='name', level='overlay',\n",
    "        x_offset=0, y_offset=0, text_font_size='8pt'\n",
    "    )\n",
    "    \n",
    "    p.add_layout(\n",
    "        bm.LabelSet(\n",
    "            source=year_source, text_color='black', text_align='center', text_baseline='middle', **text_opts\n",
    "        )\n",
    "    )\n",
    "    p.add_layout(\n",
    "        bm.LabelSet(\n",
    "            source=topic_source, text_color='black', text_align='center', text_baseline='middle', **text_opts\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return p\n",
    "\n",
    "def main_topic_year_network(state):\n",
    "    \n",
    "    wc = wf.BaseWidgetUtility(\n",
    "        n_topics=state.n_topics,\n",
    "        text_id='nx_id1',\n",
    "        text=wf.create_text_widget('nx_id1', style=\"display: inline; height='400px'\"),\n",
    "        year=widgets.IntSlider(description='Year', min=state.min_year, max=state.max_year, step=1, value=state.min_year, continues_update=False),\n",
    "        pivot_column=widgets.Dropdown(\n",
    "            options={\n",
    "                'SOU report': 'report_name',\n",
    "                'Year': 'year'\n",
    "            },\n",
    "            value='report_name',\n",
    "            description='Pivot'\n",
    "        ),\n",
    "        scale=widgets.FloatSlider(description='Scale', min=0.0, max=1.0, step=0.01, value=0.1, continues_update=False),\n",
    "        threshold=widgets.FloatSlider(description='Threshold', min=0.0, max=1.0, step=0.01, value=0.50, continues_update=False),\n",
    "        output_format=widgets.Dropdown(\n",
    "            options={'Network': 'network', 'Table': 'table'},\n",
    "            value='network',\n",
    "            description='Output'\n",
    "        ),\n",
    "        layout=widgets.Dropdown(\n",
    "            options=list(layout_algorithms.keys()),\n",
    "            value='Fruchterman-Reingold',\n",
    "            description='Layout'\n",
    "        ),\n",
    "        progress=widgets.IntProgress(min=0, max=4, step=1, value=0, layout=widgets.Layout(width=\"40%\"))\n",
    "    ) \n",
    "    \n",
    "    wc.previous = wc.create_prev_id_button('year', 10000)\n",
    "    wc.next = wc.create_next_id_button('year', 10000)    \n",
    "    \n",
    "    def display_topic_year_network(\n",
    "        layout_algorithm,\n",
    "        threshold=0.50,\n",
    "        scale=1.0,\n",
    "        pivot_column='report_name',\n",
    "        year=None,\n",
    "        output_format='network'\n",
    "    ):\n",
    "        wc.progress.value = 1\n",
    "        \n",
    "        titles = state.get_topic_titles()\n",
    "        filters = []\n",
    "        if year is not None:\n",
    "            filters = [ { 'column': 'year', 'value': year }]\n",
    "        filters = filters + [ { 'query': 'weight >= {}'.format(threshold) } ]\n",
    "        df = state.get_document_topic_weight_by_pivot_column(pivot_column, key='max', filters=filters)\n",
    "        df = df[df.weight > threshold]\n",
    "        \n",
    "        wc.progress.value = 2\n",
    "\n",
    "        network = NetworkUtility.create_bipartite_network(df, pivot_column, 'topic_id')\n",
    "        \n",
    "        wc.progress.value = 3\n",
    "\n",
    "        if output_format == 'network':\n",
    "            \n",
    "            args = PlotNetworkUtility.layout_args(layout_algorithm, network, scale)\n",
    "            layout = (layout_algorithms[layout_algorithm])(network, **args)\n",
    "            \n",
    "            wc.progress.value = 4\n",
    "            \n",
    "            p = plot_topic_year_network(network, layout, scale=scale, titles=titles)\n",
    "            show(p)\n",
    "\n",
    "        elif output_format == 'table':\n",
    "            print(df.shape)\n",
    "            display(df)\n",
    "        else:\n",
    "            display(pivot_ui(df))\n",
    "\n",
    "        wc.progress.value = 0\n",
    "\n",
    "    iw = widgets.interactive(\n",
    "        display_topic_year_network,\n",
    "        layout_algorithm=wc.layout,\n",
    "        threshold=wc.threshold,\n",
    "        scale=wc.scale,\n",
    "        pivot_column=wc.pivot_column,\n",
    "        year=wc.year,\n",
    "        output_format=wc.output_format\n",
    "    )\n",
    "\n",
    "    display(widgets.VBox([\n",
    "        wc.text,\n",
    "        widgets.HBox([wc.layout, wc.year, wc.previous, wc.next]),\n",
    "        widgets.HBox([wc.pivot_column, wc.scale]),\n",
    "        widgets.HBox([wc.output_format, wc.threshold, wc.progress]),\n",
    "        iw.children[-1]\n",
    "    ]))\n",
    "    iw.update()\n",
    "    \n",
    "main_topic_year_network(state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Trends - Heatmap\n",
    "- The topic shares  displayed as a scattered heatmap plot using gradient color based on topic's weight in document.\n",
    "- [Stanford’s Termite software](http://vis.stanford.edu/papers/termite) uses a similar visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4e56caf8ed943918a416b6cb62289ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Pivot', index=1, layout=Layout(width='200px'), options={'Y…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot_topic_relevance_by_year\n",
    "\n",
    "def setup_glyph_coloring(df):\n",
    "    max_weight = df.weight.max()\n",
    "    #colors = list(reversed(bokeh.palettes.Greens[9]))\n",
    "    colors = [\"#efefef\", \"#75968f\", \"#a5bab7\", \"#c9d9d3\", \"#e2e2e2\", \"#dfccce\", \"#ddb7b1\", \"#cc7878\",\n",
    "              \"#933b41\", \"#550b1d\"]\n",
    "    mapper = bm.LinearColorMapper(palette=colors, low=df.weight.min(), high=max_weight)\n",
    "    color_transform = transform('weight', mapper)\n",
    "    color_bar = bm.ColorBar(color_mapper=mapper, location=(0, 0),\n",
    "                         ticker=bm.BasicTicker(desired_num_ticks=len(colors)),\n",
    "                         formatter=bm.PrintfTickFormatter(format=\" %5.2f\"))\n",
    "    return color_transform, color_bar\n",
    "\n",
    "def plot_topic_relevance_by_year(df, xs, ys, flip_axis, glyph, titles, text_id):\n",
    "\n",
    "    line_height = 7\n",
    "    if flip_axis is True:\n",
    "        xs, ys = ys, xs\n",
    "        line_height = 10\n",
    "    \n",
    "    ''' Setup axis categories '''\n",
    "    x_range = list(map(str, df[xs].unique()))\n",
    "    y_range = list(map(str, df[ys].unique()))\n",
    "    \n",
    "    ''' Setup coloring and color bar '''\n",
    "    color_transform, color_bar = setup_glyph_coloring(df)\n",
    "    \n",
    "    source = ColumnDataSource(df)\n",
    "\n",
    "    plot_height = max(len(y_range) * line_height, 500)\n",
    "    \n",
    "    p = figure(title=\"Topic heatmap\", tools=TOOLS, toolbar_location=\"right\", x_range=x_range,\n",
    "           y_range=y_range, x_axis_location=\"above\", plot_width=1000, plot_height=plot_height)\n",
    "\n",
    "    args = dict(x=xs, y=ys, source=source, alpha=1.0, hover_color='red')\n",
    "    \n",
    "    if glyph == 'Circle':\n",
    "        cr = p.circle(color=color_transform, **args)\n",
    "    else:\n",
    "        cr = p.rect(width=1, height=1, line_color=None, fill_color=color_transform, **args)\n",
    "\n",
    "    p.x_range.range_padding = 0\n",
    "    p.ygrid.grid_line_color = None\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.axis.axis_line_color = None\n",
    "    p.axis.major_tick_line_color = None\n",
    "    p.axis.major_label_text_font_size = \"5pt\"\n",
    "    p.axis.major_label_standoff = 0\n",
    "    p.xaxis.major_label_orientation = 1.0\n",
    "    p.add_layout(color_bar, 'right')\n",
    "    \n",
    "    p.add_tools(bm.HoverTool(tooltips=None, callback=wf.WidgetUtility.glyph_hover_callback(\n",
    "        source, 'topic_id', titles.index, titles, text_id), renderers=[cr]))\n",
    "    \n",
    "    return p\n",
    "\n",
    "def topic_heatmap_main(state):\n",
    "    \n",
    "    def display_topic_relevance_by_year(state, key='max', pivot_column=None, year=None, flip_axis=False, glyph='Circle', wdgs=None):\n",
    "        \n",
    "        try:\n",
    "            wdgs.reset()\n",
    "            wdgs.forward()\n",
    "            \n",
    "            titles = ModelUtility.get_topic_titles(state.topic_token_weights, n_words=100)\n",
    "            wdgs.forward()\n",
    "\n",
    "            year = (year or 0)\n",
    "            \n",
    "            pivot_column = 'year' if year > 0 else (pivot_column or 'report_name')\n",
    "            filters = [{'column': 'year', 'values': [year]}] if year > 0 else []\n",
    "            \n",
    "            df = state.get_document_topic_weight_by_pivot_column(pivot_column, key, filters=filters)\n",
    "            \n",
    "            wdgs.forward()\n",
    "            \n",
    "            df[pivot_column] = df[pivot_column].astype(str)\n",
    "            df['topic_id'] = df.topic_id.astype(str)\n",
    "            \n",
    "            wdgs.forward()\n",
    "            \n",
    "            p = plot_topic_relevance_by_year(df, xs=pivot_column, ys='topic_id', flip_axis=flip_axis, glyph=glyph, titles=titles, text_id='topic_relevance')\n",
    "            \n",
    "            show(p)\n",
    "            wdgs.reset()\n",
    "        except Exception as ex:\n",
    "            raise\n",
    "            logger.error(ex)\n",
    "        finally:\n",
    "            wdgs.reset()\n",
    "\n",
    "    wc = wf.BaseWidgetUtility(\n",
    "        text_id='topic_relevance',\n",
    "        text=wf.create_text_widget('topic_relevance'),\n",
    "        year=widgets.Dropdown(options=state.years, value=None, description='Year', layout=widgets.Layout(width=\"140px\")),\n",
    "        pivot_column=widgets.Dropdown(\n",
    "            options={\n",
    "                'SOU report': 'report_name',\n",
    "                # 'LDA document': 'document_id',\n",
    "                'Year': 'year'\n",
    "            },\n",
    "            value='report_name',\n",
    "            description='Pivot',\n",
    "            layout=widgets.Layout(width=\"200px\")\n",
    "        ),\n",
    "        aggregate=widgets.Dropdown(options=['max', 'mean'], value='max', description='Aggregate', layout=widgets.Layout(width=\"180px\")),\n",
    "        progress=widgets.IntProgress(min=0, max=4, step=1, value=0, layout=widgets.Layout(width=\"35%\")),\n",
    "        glyph=widgets.Dropdown(options=['Circle', 'Square'], value='Square', description='Glyph', layout=widgets.Layout(width=\"180px\")),\n",
    "        flip_axis=widgets.ToggleButton(value=True, description='Flip XY', tooltip='Flip X and Y axis', icon='', layout=widgets.Layout(width=\"80px\"))\n",
    "    )\n",
    "\n",
    "    iw = widgets.interactive(\n",
    "        display_topic_relevance_by_year,\n",
    "        state=widgets.fixed(state),\n",
    "        key=wc.aggregate,\n",
    "        pivot_column=wc.pivot_column,\n",
    "        year=wc.year,\n",
    "        glyph=wc.glyph,\n",
    "        flip_axis=wc.flip_axis,\n",
    "        wdgs=widgets.fixed(wc)\n",
    "    )\n",
    "\n",
    "    display(widgets.VBox([\n",
    "        widgets.HBox([wc.pivot_column, wc.year, wc.aggregate, wc.flip_axis, wc.glyph, wc.progress ]),\n",
    "        wc.text,\n",
    "        iw.children[-1]\n",
    "    ]))\n",
    "\n",
    "    iw.update()\n",
    "            \n",
    "topic_heatmap_main(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Co-Occurrence\n",
    "- Computes weighted graph of topics co-occurring in the same document.\n",
    "- Topics are defined as co-occurring if they exist in the same document both having weights within threshold range.\n",
    "- Weight are number of co-occurrences (binary yes or no).\n",
    "- Node size reflects topic proportions over the entire corpus (normalized document) length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b88b5f38c45b417da5f1a60eb22683b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='cooc_id' style='line-height: 20px;'></span>\", placeholder=''), HBox(ch…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize topic co-occurrence\n",
    "\n",
    "def display_topic_co_occurrence_network(layout, threshold, min_count, scale, output_format, context, state=None, text_id=''):\n",
    "\n",
    "    try:\n",
    "        titles = state.get_topic_titles()\n",
    "\n",
    "        df = state.document_topic_weights\n",
    "        df = df[(df.weight > threshold[0])&(df.weight < threshold[1])]\n",
    "        \n",
    "        df = pd.merge(df, df, how='inner', left_on=context, right_on=context)\n",
    "        df = df.loc[(df.topic_id_x < df.topic_id_y)]\n",
    "\n",
    "        if output_format in ['network', 'gephi']:\n",
    "            if output_format == 'network':\n",
    "                df = df.groupby([df.topic_id_x, df.topic_id_y]).size().reset_index()\n",
    "                df.columns = ['source', 'target', 'weight']\n",
    "                df = df[df.weight >= min_count]\n",
    "                network = NetworkUtility.create_network(df, source_field='source', target_field='target', weight='weight')\n",
    "                p = PlotNetworkUtility.plot_network(\n",
    "                    network=network,\n",
    "                    layout_algorithm=layout,\n",
    "                    scale=scale,\n",
    "                    threshold=0.0,\n",
    "                    node_description=titles,\n",
    "                    node_proportions=state.get_topic_proportions(),\n",
    "                    weight_scale=10.0,\n",
    "                    normalize_weights=True,\n",
    "                    element_id=text_id,\n",
    "                    figsize=(900,500)\n",
    "                )\n",
    "                show(p)\n",
    "            elif output_format == 'gephi':\n",
    "                display(df)\n",
    "        elif output_format == 'table':\n",
    "            pivots = ([context] if context == 'report_name' else []) + [df.topic_id_x, df.topic_id_y]\n",
    "            df = df.groupby(pivots).size().reset_index().rename(columns={0: 'count'})\n",
    "            df = df[df['count'] >= min_count]\n",
    "            titles = pd.DataFrame(state.get_topic_titles(n_words=5, cache=False))\n",
    "            df = pd.merge(df, titles, left_on='topic_id_x', right_index=True)\n",
    "            df = pd.merge(df, titles, left_on='topic_id_y', right_index=True)\n",
    "            df = df.rename(columns={'0_x': 'Topic#1', '0_y': 'Topic#2'})\n",
    "            df.columns = [c.title() for c in df.columns]\n",
    "            display(df)\n",
    "        else:\n",
    "            display(pivot_ui(df))\n",
    "    except Exception as x:\n",
    "        raise\n",
    "        print(\"No data: please adjust filters\")\n",
    "\n",
    "def topic_co_occurance_main(state):\n",
    "\n",
    "    text_id = 'cooc_id'\n",
    "    wc = wf.BaseWidgetUtility(\n",
    "        n_topics=state.n_topics,\n",
    "        text_id=text_id,\n",
    "        text=wf.create_text_widget(text_id),\n",
    "        scale=widgets.FloatSlider(description='Scale', min=0.0, max=1.0, step=0.01, value=0.1, continues_update=False),\n",
    "        min_count=widgets.IntSlider(description='Min count', min=1, max=500, step=1, value=10, continues_update=False),\n",
    "        threshold=widgets.FloatRangeSlider(value=[0.25, 1.0], min=0, max=1.0, step=0.01, description='Threshold:', readout_format='.2f'),\n",
    "        context=widgets.Dropdown(\n",
    "            options={'SOU report': 'report_name', 'LDA document': 'document_id'},\n",
    "            value='report_name', # ['year', 'report_id']\n",
    "            description='Context',\n",
    "            layout=widgets.Layout(width='200px')\n",
    "        ),\n",
    "        output_format=widgets.Dropdown(\n",
    "            options={'Network': 'network', 'Gephi': 'gephi', 'Table': 'table'},\n",
    "            value='network',\n",
    "            description='Output',\n",
    "            layout=widgets.Layout(width='200px')\n",
    "        ),\n",
    "        layout=widgets.Dropdown(\n",
    "            options=list(layout_algorithms.keys()),\n",
    "            value='Fruchterman-Reingold',\n",
    "            description='Layout',\n",
    "            layout=widgets.Layout(width='200px')\n",
    "        ),\n",
    "        progress=widgets.IntProgress(min=0, max=4, step=1, value=0, layout=widgets.Layout(width=\"40%\"))\n",
    "    ) \n",
    "\n",
    "    iw = widgets.interactive(\n",
    "        display_topic_co_occurrence_network,\n",
    "        layout=wc.layout,\n",
    "        threshold=wc.threshold,\n",
    "        min_count=wc.min_count,\n",
    "        scale=wc.scale,\n",
    "        output_format=wc.output_format,\n",
    "        context=wc.context,\n",
    "        state=widgets.fixed(state),\n",
    "        text_id=widgets.fixed(text_id)\n",
    "    )\n",
    "\n",
    "    display(widgets.VBox([\n",
    "        wc.text,\n",
    "        widgets.HBox([wc.threshold, wc.context, wc.layout,wc.layout, wc.output_format]),\n",
    "        widgets.HBox([wc.min_count, wc.progress]),\n",
    "        iw.children[-1]\n",
    "    ]))\n",
    "    iw.update()\n",
    "    \n",
    "topic_co_occurance_main(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Similarity Network\n",
    "- Displays topic similarity based on **euclidean or cosine distances** between the **topic-to-word vectors**.\n",
    "- Please note that the computations can take some time to exceute, especially for larger LDA models.\n",
    "\n",
    "> * Compute a multi dimensional topic vector space based on the top n words for each topic. Since the subset of words differs, and their positions differs between topics they need to be aligned in common space so that 1) each vector has the same dimension (i.e. number of unique top n tokens over all topics) and 2) each token has the same position within that space. (using sklearn DictVectorizer). The vector space will have as many dimensions as the number of unique top n words over all topics.\n",
    "> * Reduce the topic vector space into a 2D space (using sklearn PCA)\n",
    "> * Normalize the 2D space (sklearn Normalizer)\n",
    "\n",
    "Note: Steps 1 to 3 above (the most time consuming) are executed whenever an option marked with an asterix is changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41170750354c46deb4617e4fa53ab4f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='nx_id3' style='line-height: 20px;'></span>\", placeholder=''), HBox(chi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization\n",
    "from scipy.spatial import distance\n",
    "from common.vectorspace_utility import VectorSpaceHelper\n",
    "\n",
    "# if 'zy_data' not in globals():\n",
    "correlation_network_state_data = types.SimpleNamespace(\n",
    "    basename=None,\n",
    "    network=None,\n",
    "    X_n_space=None,\n",
    "    X_n_space_feature_names=None,\n",
    "    distance_matrix=None,\n",
    "    metric=None,\n",
    "    topic_proportions=None,\n",
    "    n_words = 0\n",
    ")\n",
    "\n",
    "def plot_clustering_dendogram(clustering):\n",
    "    plt.figure(figsize=(16,6))\n",
    "    # https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.cluster.hierarchy.dendrogram.html\n",
    "    R = dendrogram(clustering)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def VectorSpaceHelper_compute_distance_matrix(X_n_space, metric='euclidean'):\n",
    "    # https://se.mathworks.com/help/stats/pdist.html\n",
    "    metric = metric.lower()\n",
    "    if metric == 'kullback–leibler': metric = VectorSpaceHelper.kullback_leibler_divergence\n",
    "    if metric == 'scipy.stats.entropy': metric = scipy.stats.entropy\n",
    "    #print(metric)\n",
    "    X = X_n_space.toarray() if hasattr(X_n_space, 'toarray') else X_n_space\n",
    "    #X_n_space += 0.00001\n",
    "    distances = distance.pdist(X, metric=metric)\n",
    "    #print(distances)\n",
    "    distance_matrix = distance.squareform(distances)\n",
    "    #print(distance_matrix)    \n",
    "    return distance_matrix\n",
    "\n",
    "def main_correlation_network(state, zy_data):\n",
    "\n",
    "    zy = wf.BaseWidgetUtility(\n",
    "        n_topics=state.n_topics,\n",
    "        text_id='nx_id3',\n",
    "        text=wf.create_text_widget('nx_id3'),\n",
    "        scale=wf.create_float_slider('Scale', min=0.0, max=1.0, step=0.01, value=0.1),\n",
    "        year=wf.create_int_slider(\n",
    "            description='Year', min=state.min_year, max=state.max_year, step=1, value=state.min_year\n",
    "        ),\n",
    "        n_words=wf.create_int_slider(description='#words*', min=10, max=500, step=1, value=20),\n",
    "        metric=wf.create_select_widget(label='Metric*', values=list(DISTANCE_METRICS.keys()), default='Euclidean'),\n",
    "        threshold=wf.create_float_slider('Threshold', min=0.0, max=1.0, step=0.01, value=0.01),\n",
    "        output_format=widgets.Dropdown(\n",
    "            options={'Network': 'network', 'Table': 'table'},\n",
    "            value='network',\n",
    "            description='Output',\n",
    "            layout=widgets.Layout(width='200px')\n",
    "        ),\n",
    "        layout=wf.create_select_widget('Layout', list(layout_algorithms.keys()), default='Fruchterman-Reingold'),\n",
    "        progress=wf.create_int_progress_widget(min=0, max=7, step=1, value=0, layout=widgets.Layout(width=\"90%\"))\n",
    "    ) \n",
    "    \n",
    "    def display_correlation_network(\n",
    "        layout_algorithm,\n",
    "        threshold=0.10,\n",
    "        scale=1.0,\n",
    "        metric='Euclidean',\n",
    "        n_words=200,\n",
    "        output_format='Network'\n",
    "    ):\n",
    "\n",
    "        try:\n",
    "\n",
    "            zy.progress.value = 1\n",
    "            metric = DISTANCE_METRICS[metric]\n",
    "\n",
    "            node_description = state.get_topic_titles()\n",
    "            node_proportions = state.get_topic_proportions()\n",
    "\n",
    "            zy.progress.value = 2\n",
    "            if zy_data.network is None or state.basename != zy_data.basename or zy_data.metric != metric or zy_data.n_words != n_words:\n",
    "\n",
    "                zy_data.basename = state.basename\n",
    "                zy_data.n_words = n_words\n",
    "                zy_data.X_n_space, zy_data.X_n_space_feature_names = state.compute_topic_terms_vector_space(n_words=n_words)\n",
    "\n",
    "                #print(zy_data.X_n_space.shape)\n",
    "                #print(zy_data.X_n_space_feature_names)\n",
    "                zy.progress.value = 3\n",
    "                zy_data.distance_matrix = VectorSpaceHelper_compute_distance_matrix(zy_data.X_n_space, metric=metric)\n",
    "                zy_data.network = None\n",
    "\n",
    "            edges_data = VectorSpaceHelper.lower_triangle_iterator(zy_data.distance_matrix, threshold)\n",
    "            \n",
    "            #df = pd.DataFrame(edges_data, columns=['x', 'y', 'weight']).groupby(['weight']).size()\n",
    "            #display(df.head())\n",
    "            #df.plot()\n",
    "            zy.progress.value = 4\n",
    "            if output_format == 'table':\n",
    "                df = pd.DataFrame(edges_data, columns=['x', 'y', 'weight'])\n",
    "                zy.progress.value = 5\n",
    "                display(df)\n",
    "            else:\n",
    "                zy.progress.value = 5\n",
    "                if zy_data.network is None:\n",
    "                    zy_data.network = NetworkUtility.create_network_from_xyw_list(edges_data) # zy_data.distance_matrix)\n",
    "                zy.progress.value = 6\n",
    "                p = PlotNetworkUtility.plot_network(\n",
    "                    network=zy_data.network,\n",
    "                    layout_algorithm=layout_algorithm,\n",
    "                    scale=scale,\n",
    "                    threshold=threshold,\n",
    "                    node_description=node_description,\n",
    "                    node_proportions=node_proportions,\n",
    "                    element_id='nx_id3',\n",
    "                    figsize=(1000,600)\n",
    "                )\n",
    "                zy.progress.value = 6\n",
    "                show(p)\n",
    "\n",
    "            zy.progress.value = 7\n",
    "            zy.progress.value = 0\n",
    "        except Exception as ex:\n",
    "            logger.error(ex)\n",
    "            print('Empty set: please change filters')\n",
    "            zy.progress.value = 0\n",
    "\n",
    "\n",
    "    wy = widgets.interactive(\n",
    "        display_correlation_network,\n",
    "        layout_algorithm=zy.layout,\n",
    "        threshold=zy.threshold,\n",
    "        scale=zy.scale,\n",
    "        metric=zy.metric,\n",
    "        n_words=zy.n_words,\n",
    "        output_format=zy.output_format\n",
    "    )\n",
    "\n",
    "    display(widgets.VBox(\n",
    "        (zy.text, ) +\n",
    "        (widgets.HBox((zy.threshold,) + (zy.metric,) + (zy.output_format,)),) +\n",
    "        (widgets.HBox((zy.n_words,) + (zy.layout,) + (zy.scale,)),) +\n",
    "        (zy.progress,) +\n",
    "        (wy.children[-1],)))\n",
    "\n",
    "    wy.update()\n",
    "\n",
    "    \n",
    "main_correlation_network(state, correlation_network_state_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some (assorted) references\n",
    "\n",
    "> Blei: https://scholar.google.com/citations?user=8OYE6iEAAAAJ\n",
    "\n",
    "- Blei, 2003: Latent dirichlet allocation [PDF](http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf)\n",
    "- Blei, 2012: Probabilistic topic models [PDF](https://pdfs.semanticscholar.org/01f3/290d6f3dee5978a53d9d2362f44daebc4008.pdf)\n",
    "- Blei, 2006: Dynamic topic models [PDF](http://repository.cmu.edu/cgi/viewcontent.cgi?article=2036&context=compsci)\n",
    "- Introduction to Probabilistic Topic Models: [PDF](http://menome.com/wp/wp-content/uploads/2014/12/Blei2011.pdf)\n",
    "- Mcauliffe, Blei, 2008: Supervised topic models [PDF](http://papers.nips.cc/paper/3328-supervised-topic-models.pdf)\n",
    "- Grimmer, 2013: Text as Data: The Promise and Pitfalls of Automatic Content Analysis Methods for Politica\n",
    "[PDF](http://www.jstor.org/stable/pdf/24572662.pdf?casa_token=PnEPVj2gkkwAAAAA:_Vg_oSs-p6gtYvjJ3eEDUQB7UsakHQtBOdFIdeJxRpuGH5-7tq09fkUGxQ0-Bek5X2uOSya35-MoEo-cPo-K5DM1W-z1R0UppL6OqP53y6SNS7alAl8)\n",
    "- Chuang, 2013: Topic Model Diagnostics: Assessing Domain Relevance via Topical Alignment\n",
    "[PDF](http://vis.stanford.edu/files/2013-TopicModelDiagnostics-ICML.pdf)\n",
    "[Sup](http://vis.stanford.edu/files/2013-TopicalModelDiagnostics-SuppMaterial.pdf)\n",
    "- Lecture, Blei, 2009: [Video](http://videolectures.net/mlss09uk_blei_tm/) \n",
    "- Prof. David Blei - Probabilistic Topic Models and User Behavior [YoutTube](https://www.youtube.com/watch?v=FkckgwMHP2s)\n",
    "- PyData Berlin 2017 (Matti Lyra) [YouTube](https://www.youtube.com/watch?v=FkckgwMHP2s) [YouTube](https://www.youtube.com/watch?v=Dv86zdWjJKQ)\n",
    "[NB](https://github.com/mattilyra/pydataberlin-2017/blob/master/notebook/EvaluatingUnsupervisedModels.ipynb)\n",
    "- Probabilistic Topic Models: [PDF](https://pdfs.semanticscholar.org/01f3/290d6f3dee5978a53d9d2362f44daebc4008.pdf) [PDF](https://mimno.infosci.cornell.edu/info6150/readings/Blei2012.pdf)\n",
    "- Visualizing Topic Models: [PDF](http://ajbc.io/projects/papers/ChaneyBlei2012.pdf)\n",
    "- Topic models: [PDF](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.463.1205&rep=rep1&type=pdf#page=96)\n",
    "- Sievert, LDAvis: A method for visualizing and interpreting topics [PDF](http://www.aclweb.org/anthology/W14-3110)\n",
    "- Ted Underwood: [Blog](https://tedunderwood.com/category/methodology/topic-modeling/bayesian-topic-modeling/)\n",
    "- Stanford Topic Modeling Toolbox: [Link](https://nlp.stanford.edu/software/tmt/tmt-0.4/)\n",
    "- Blog, Naomi Saphra: Understanding Latent Dirichlet Allocation [Link](https://nsaphra.github.io/2012/07/09/LDA/)\n",
    "- blog.bogatron.net: Visualizing Dirichlet Distributions with Matplotlib [Link](http://blog.bogatron.net/blog/2014/02/02/visualizing-dirichlet-distributions/)\n",
    "- Wikipedia: [Topic Model](https://en.wikipedia.org/wiki/Topic_model) [LDA](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation)\n",
    "[Dirichlet distribution](https://en.wikipedia.org/wiki/Dirichlet_distribution)\n",
    "- Visualization using dimensionality reduction (e.g. T-SNE, PCA) [Shusen Liu, 2016], (pitfalls)\n",
    "http://qpleple.com/bib/#Chuang12\n",
    "http://qpleple.com/word-relevance/\n",
    "- Finding scientific topics: [PDF](http://psiexp.ss.uci.edu/research/papers/sciencetopics.pdf)\n",
    "\n",
    "### Powered by\n",
    "<img src=\"./images/powered_by.svg\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
